{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd3eb2-33a8-4dc9-b9cc-e37add9c4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series of precipitation\n",
    "# Only 2 models (50 member ENS and Neighbourhood from DestinE Extremes DT)\n",
    "# Obs from STVL\n",
    "# The closest synop station is found for the input location, model data is plotted for the station location\n",
    "# Automatic MARS retrieval is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a42e8-d26c-4aea-b166-90a2c232bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MIR_GRIB_INPUT_BUFFER_SIZE=7688961960\n",
    "%env MARS_READANY_BUFFER_SIZE=7688961960\n",
    "%env MIR_CACHE_PATH=${SCRATCH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metview as mv\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from matplotlib.patches import Patch  # Import Patch to create custom legend handles\n",
    "import vtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76382f46-c0cf-4c24-9154-a62f8553d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDateFormatter(mdates.DateFormatter):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, x, pos=0):\n",
    "        if x.hour == 0 and x.minute == 0:\n",
    "            return x.strftime('%Y-%m-%d %H UTC')\n",
    "        else:\n",
    "            return x.strftime('%H UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-evanescence",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adate = datetime(2025,5,2)                  # Forecast initialisation day\n",
    "atime = 0                                    # Forecast initialisation time\n",
    "\n",
    "# the ensemble size (perturbed members)\n",
    "ens_num_oper = 50\n",
    "\n",
    "# location_in = [47.4979, 19.0402]   # Budapest, Hungary\n",
    "# location_name = \"Budapest, Hungary\"\n",
    "\n",
    "# location_in = [45.4384, 10.9917]  \n",
    "# location_name = \"Verona, Italy\"\n",
    "\n",
    "# location_in = [50.7374, 7.0982]  \n",
    "# location_name = \"Bonn, Germany\"   # North of Konigswinter\n",
    "\n",
    "location_in = [50.85949, 7.13899]  \n",
    "location_name = \"CGN Airport, Germany\"\n",
    "\n",
    "path_in_EDT = \"/ec/vol/destine/neighbourhood/edt/\"\n",
    "path_in_ENS = \"/ec/vol/destine/neighbourhood/oper_ENS_9km/\"\n",
    "path_in_NB = \"/ec/vol/destine/neighbourhood/percentile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893d7b0-db46-485e-b934-d90b1604b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nearest synop to the requested location\n",
    "\n",
    "end_date = adate + timedelta(hours=120)\n",
    "\n",
    "my_dates = pd.date_range(adate,end_date,freq=\"6h\")\n",
    "\n",
    "# r = mv.stvl(\n",
    "r = vtb.media.stvl_retrieve( \n",
    "    sources=\"synop\",\n",
    "    parameter=\"tp\",\n",
    "    date=my_dates,\n",
    "    #times=6,\n",
    "    period=pd.Timedelta(hours=6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec39536-2e92-47e7-84d2-1f740467602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = r.to_metview()[0]\n",
    "dist = mv.distance(r3, location_in)\n",
    "dd = dist.values()\n",
    "loc_closest_index = np.nanargmin(dd)\n",
    "rr = r.to_dataframe()\n",
    "location = [rr.latitude[loc_closest_index], rr.longitude[loc_closest_index]]  # location of closest synop (model values will be retrived for this location)\n",
    "obs_loc = rr.values[loc_closest_index][4:]     # vector of observation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d33fa-581f-4aaf-a514-fc0fb40db0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0e597-e13b-4082-997a-44d8f2c77c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[loc_closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41e9e7-b839-4f39-be90-fdd0c31345c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_in1cf = adate.strftime(\"%Y%m%d\")  + \"_cf.grib\" \n",
    "path_file_in1pf = adate.strftime(\"%Y%m%d\")  + \"_pf.grib\" \n",
    "path_file_in1edt = adate.strftime(\"%Y%m%d\")  + \".grib\" \n",
    "\n",
    "print(path_file_in1cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174d424-fedd-45ac-9a2c-45d945624f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download oper ENS data from MARS if not downloaded already\n",
    "if os.path.isfile(path_in_ENS + path_file_in1pf):\n",
    "    print(\"ENS file already exists, no MARS retrieval. : \", path_in_ENS + path_file_in1pf)\n",
    "else:\n",
    "    print(\"Retriving ENS data from  MARS\")\n",
    "    ret_field = mv.retrieve(\n",
    "        date= adate,\n",
    "        time= 0,\n",
    "        step= [0,\"to\",120,\"by\",6],\n",
    "        type= \"pf\",\n",
    "        number=[1,\"to\",50],\n",
    "        class_= \"od\",\n",
    "        stream= \"enfo\",\n",
    "        levtype= \"sfc\",\n",
    "        expver= 1,\n",
    "        param=\"228.128\"     # total precipitation\n",
    "        \n",
    "    )\n",
    "\n",
    "    # save to file\n",
    "    print(\"writing retrieved file: \", path_in_ENS + path_file_in1pf)\n",
    "    mv.write(path_in_ENS + path_file_in1pf,ret_field)\n",
    "\n",
    "    ret_field = mv.retrieve(\n",
    "        date= adate,\n",
    "        time= 0,\n",
    "        step= [0,\"to\",120,\"by\",6],\n",
    "        type= \"cf\",\n",
    "        class_= \"od\",\n",
    "        stream= \"enfo\",\n",
    "        levtype= \"sfc\",\n",
    "        expver= 1,\n",
    "        param=\"228.128\"     # total precipitation\n",
    "        \n",
    "    )\n",
    "\n",
    "    # save to file\n",
    "    print(\"writing retrieved file: \", path_in_ENS + path_file_in1cf)\n",
    "    mv.write(path_in_ENS + path_file_in1cf,ret_field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_grib1cf = mv.read(path_in_ENS + path_file_in1cf)\n",
    "\n",
    "file_grib1pf = mv.read(path_in_ENS + path_file_in1pf)\n",
    "\n",
    "file_grib1 = mv.merge(file_grib1cf, file_grib1pf)\n",
    "\n",
    "file_grib1edt = mv.read(path_in_EDT + path_file_in1edt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4d789-6453-45df-89ea-98f6f2ebc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1cf = file_grib1cf.select(\n",
    "     shortName=\"tp\",\n",
    "     )\n",
    "\n",
    "tp1edt = file_grib1edt.select(\n",
    "     shortName=\"tp\",\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = file_grib1.select(\n",
    "     shortName=\"tp\",\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331ed53-ffd8-43d2-a2ab-58d116e6b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time series for the pertubations (as a 2D ndarray)\n",
    "tp1_pert_loc = []\n",
    "for i in range(1, ens_num_oper + 1):\n",
    "    tp1_pert = tp1.select(number=i, type=\"pf\")\n",
    "    tp1_pert_loc.append(mv.nearest_gridpoint(tp1_pert, location))\n",
    "tp1_pert_loc_arr = np.array(tp1_pert_loc)\n",
    "\n",
    "# extract time series for the control forecast (as 1D array)\n",
    "tp1_ctr = tp1.select(type=\"cf\")\n",
    "tp1_ctr_loc_arr = np.array(mv.nearest_gridpoint(tp1_ctr, location))\n",
    "\n",
    "# extract time series for EDT forecast (as 1D array)\n",
    "tp1_edt_loc_arr = np.array(mv.nearest_gridpoint(tp1edt, location))\n",
    "\n",
    "del tp1_pert_loc,tp1,file_grib1\n",
    "\n",
    "tp1_pert_loc_arr=tp1_pert_loc_arr*1000\n",
    "tp1_ctr_loc_arr=tp1_ctr_loc_arr*1000\n",
    "tp1_edt_loc_arr=tp1_edt_loc_arr*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3670ecb-fd39-4df4-8dc3-5143a643d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp1_pert_loc_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e9267-b2c7-4f8d-9f74-ecbbddc59acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ENS mean series\n",
    "tp1_mean = np.vstack([tp1_pert_loc_arr, tp1_ctr_loc_arr]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773e295-8acc-4c69-b053-b6510844b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata for the title\n",
    "meta = mv.grib_get(tp1_pert[0], [\"name\", \"level\", \"date\", \"time\"])[0]\n",
    "\n",
    "# get the valid times for the time series points\n",
    "d_times = mv.valid_date(tp1_pert)\n",
    "\n",
    "# determine number of timesteps\n",
    "ts_num = len(tp1_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911d8ab-3b9c-475c-bd36-0f301739f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1ca76-9ea8-41f0-96ce-326791c954aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp1_pert_loc_arr[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56b1d3-4832-478b-88bc-4ecfef7e6099",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate 24-hour accumulation\n",
    "def calculate_24h_accumulation(data):\n",
    "    return data[:, 4:] - data[:, :-4]  # Take the difference every 4 steps (24-hour accumulation)\n",
    "\n",
    "# Calculate 6-hour accumulation\n",
    "def calculate_6h_accumulation(data):\n",
    "    return data[:, 1:] - data[:, :-1]  # Take the difference between consecutive time steps\n",
    "\n",
    "# Calculate 6-hour accumulation\n",
    "def calculate_6h_accumulation_ctr(data):\n",
    "    return data[1:] - data[:-1]  # Take the difference between consecutive time steps\n",
    "\n",
    "# Calculate accumulation for each system\n",
    "tp1_6h_accum = calculate_6h_accumulation(tp1_pert_loc_arr)\n",
    "tp1_ctr_6h_accum = calculate_6h_accumulation_ctr(tp1_ctr_loc_arr)\n",
    "tp1_edt_6h_accum = calculate_6h_accumulation_ctr(tp1_edt_loc_arr)\n",
    "\n",
    "# Use the original time array for 24-hour intervals (no shift for end-of-period accumulation)\n",
    "d_times_24h = np.array(d_times[4:])  # Keep times aligned with the end of the accumulation period\n",
    "d_times = np.array(d_times)  # Keep times aligned with the end of the accumulation period\n",
    "\n",
    "# Function to calculate percentiles and mean\n",
    "def calculate_percentiles(data):\n",
    "    p1 = np.percentile(data, 1, axis=0)\n",
    "    p25 = np.percentile(data, 25, axis=0)\n",
    "    p75 = np.percentile(data, 75, axis=0)\n",
    "    p99 = np.percentile(data, 99, axis=0)\n",
    "    p50 = np.percentile(data, 50, axis=0)\n",
    "    mean = np.mean(data, axis=0)\n",
    "    return p1, p25, p75, p99, p50, mean\n",
    "\n",
    "# Select only times that are at midnight (0 hours) for the end of the accumulation period, or every 6h if we have 6-h accumulations\n",
    "# midnight_indices = np.where(d_times_24h.astype('datetime64[m]').astype(int) % 1440 == 0)[0]  # Check for midnight (0 minutes)\n",
    "# d_times_midnight = d_times_24h[midnight_indices]\n",
    "six_hour_indices = np.where(d_times.astype('datetime64[m]').astype(int) % 360 == 0)[0]  # Check for every 6 hours (360 minutes)\n",
    "d_times_six_hour = d_times[six_hour_indices]\n",
    "\n",
    "# Calculate percentiles and mean for each system\n",
    "tp1_p1, tp1_p25, tp1_p75, tp1_p99, tp1_p50, tp1_mean = calculate_percentiles(tp1_6h_accum)\n",
    "# tp2_p1, tp2_p25, tp2_p75, tp2_p99, tp2_p50, tp2_mean = calculate_percentiles(tp2_6h_accum)\n",
    "# tp3_p1, tp3_p25, tp3_p75, tp3_p99, tp3_p50, tp3_mean = calculate_percentiles(tp3_6h_accum)\n",
    "\n",
    "valid_six_hour_indices = [i for i in six_hour_indices if i < len(tp1_p1)]\n",
    "print(valid_six_hour_indices)\n",
    "\n",
    "# Filter the percentiles and mean for plotting at midnight only\n",
    "tp1_midnight_p1 = tp1_p1[valid_six_hour_indices]\n",
    "tp1_midnight_p25 = tp1_p25[valid_six_hour_indices]\n",
    "tp1_midnight_p75 = tp1_p75[valid_six_hour_indices]\n",
    "tp1_midnight_p99 = tp1_p99[valid_six_hour_indices]\n",
    "tp1_midnight_p50 = tp1_p50[valid_six_hour_indices]\n",
    "tp1_midnight_mean = tp1_mean[valid_six_hour_indices]\n",
    "\n",
    "tp1_midnight_ctr = tp1_ctr_6h_accum[valid_six_hour_indices]\n",
    "tp1_midnight_edt = tp1_edt_6h_accum[valid_six_hour_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cecb07-f775-408b-80dd-0d65936ba067",
   "metadata": {},
   "source": [
    "## Extract info neighbourhood technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d17aaf-7de9-4223-a6f8-cecc12bebaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=adate.strftime(\"%Y%m%d\") \n",
    "step_start=6           # first lead time\n",
    "step_end=120            # last lead time\n",
    "prec_acc=6              # precip accumulation period\n",
    "\n",
    "my_point = location\n",
    "\n",
    "my_perc1=1    # percentile value \n",
    "my_perc2=25    # percentile value \n",
    "my_perc3=75    # percentile value \n",
    "my_perc4=99    # percentile value \n",
    "my_perc5=50    # percentile value \n",
    "\n",
    "# These should not be changed\n",
    "NB_radius=\"VR\"         # neighbourhood search radius in km\n",
    "NB_time=0              # neighbourhood search in time (+-prec_acc)\n",
    "\n",
    "# read grib data \n",
    "file_in1 = path_in_NB + \"NB_tp6h_p\" + str(float(my_perc1)) + \"_r\" + str(NB_radius) + \"_ST\" + str(NB_time) + \"_\" + date + \"_step_\" + str(step_start) + \"-\" + str(step_end) + \".grib2\"\n",
    "f1=mv.read(file_in1)\n",
    "file_in2 = path_in_NB + \"NB_tp6h_p\" + str(float(my_perc2)) + \"_r\" + str(NB_radius) + \"_ST\" + str(NB_time) + \"_\" + date + \"_step_\" + str(step_start) + \"-\" + str(step_end) + \".grib2\"\n",
    "f2=mv.read(file_in2)\n",
    "file_in3 = path_in_NB + \"NB_tp6h_p\" + str(float(my_perc3)) + \"_r\" + str(NB_radius) + \"_ST\" + str(NB_time) + \"_\" + date + \"_step_\" + str(step_start) + \"-\" + str(step_end) + \".grib2\"\n",
    "f3=mv.read(file_in3)\n",
    "file_in4 = path_in_NB + \"NB_tp6h_p\" + str(float(my_perc4)) + \"_r\" + str(NB_radius) + \"_ST\" + str(NB_time) + \"_\" + date + \"_step_\" + str(step_start) + \"-\" + str(step_end) + \".grib2\"\n",
    "f4=mv.read(file_in4)\n",
    "file_in5 = path_in_NB + \"NB_tp6h_p\" + str(float(my_perc5)) + \"_r\" + str(NB_radius) + \"_ST\" + str(NB_time) + \"_\" + date + \"_step_\" + str(step_start) + \"-\" + str(step_end) + \".grib2\"\n",
    "f5=mv.read(file_in5)\n",
    "\n",
    "perc_lst1 = []   # list containing percentile values for all lead times\n",
    "perc_lst2 = []   # list containing percentile values for all lead times\n",
    "perc_lst3 = []   # list containing percentile values for all lead times\n",
    "perc_lst4 = []   # list containing percentile values for all lead times\n",
    "perc_lst5 = []   # list containing percentile values for all lead times\n",
    "\n",
    "# Loop over all lead times\n",
    "for my_step in range(step_start, step_end+1,prec_acc):\n",
    "    perc_NB1 = f1.select(\n",
    "        shortName=\"tp\",\n",
    "        stepRange=str(my_step-prec_acc)+\"-\"+str(my_step),\n",
    "        )\n",
    "    perc_NB_point1 = mv.nearest_gridpoint(perc_NB1, my_point)\n",
    "    perc_lst1.append(perc_NB_point1)\n",
    "\n",
    "    perc_NB2 = f2.select(\n",
    "        shortName=\"tp\",\n",
    "        stepRange=str(my_step-prec_acc)+\"-\"+str(my_step),\n",
    "        )\n",
    "    perc_NB_point2 = mv.nearest_gridpoint(perc_NB2, my_point)\n",
    "    perc_lst2.append(perc_NB_point2)\n",
    "\n",
    "    perc_NB3 = f3.select(\n",
    "        shortName=\"tp\",\n",
    "        stepRange=str(my_step-prec_acc)+\"-\"+str(my_step),\n",
    "        )\n",
    "    perc_NB_point3 = mv.nearest_gridpoint(perc_NB3, my_point)\n",
    "    perc_lst3.append(perc_NB_point3)\n",
    "\n",
    "    perc_NB4 = f4.select(\n",
    "        shortName=\"tp\",\n",
    "        stepRange=str(my_step-prec_acc)+\"-\"+str(my_step),\n",
    "        )\n",
    "    perc_NB_point4 = mv.nearest_gridpoint(perc_NB4, my_point)\n",
    "    perc_lst4.append(perc_NB_point4)\n",
    "\n",
    "    perc_NB5 = f5.select(\n",
    "        shortName=\"tp\",\n",
    "        stepRange=str(my_step-prec_acc)+\"-\"+str(my_step),\n",
    "        )\n",
    "    perc_NB_point5 = mv.nearest_gridpoint(perc_NB5, my_point)\n",
    "    perc_lst5.append(perc_NB_point5)\n",
    "    \n",
    "# Convert date to a datetime object\n",
    "initial_date = datetime.strptime(date, \"%Y%m%d\")\n",
    "\n",
    "# Generate the datetime list\n",
    "times_nearest = [initial_date + timedelta(hours=step) for step in range(step_start, step_end + prec_acc, prec_acc)]\n",
    "# Print the resulting times for debugging\n",
    "print(times_nearest) \n",
    "print(perc_lst1) \n",
    "print(perc_lst2) \n",
    "print(perc_lst3) \n",
    "print(perc_lst4) \n",
    "print(perc_lst5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b39fb-76c0-4406-9235-9678baf42ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ab08a-5025-4c16-b9aa-40fc8c228295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define more opaque colors for each system\n",
    "color1 = 'deepskyblue'  # A more distinct shade of blue for system 1 (ENS 48r1)\n",
    "#color1='blue'\n",
    "color2 = 'salmon'       # A more distinct shade of red for system 2 (49r1 ENS)\n",
    "color3 = 'mediumseagreen'  # A more distinct shade of green for system 3 (DestinE 10 ens)\n",
    "\n",
    "# Plot shaded areas for tp1_pert_loc_arr (ENS 50)\n",
    "ax.fill_between(d_times_six_hour[1:], tp1_midnight_p1, tp1_midnight_p99, color=color1, alpha=0.4)  # Increased opacity\n",
    "ax.fill_between(d_times_six_hour[1:], tp1_midnight_p25, tp1_midnight_p75, color=color1, alpha=0.6)  # Increased opacity\n",
    "ax.plot(d_times_six_hour[1:], tp1_midnight_p50, color='blue', lw=2.5, label='9km ENS', zorder=10)\n",
    "ax.plot(d_times_six_hour[1:], tp1_midnight_ctr, color='blue', lw=2.5, label='9km control', zorder=10, linestyle = 'dashed')   # control forecast\n",
    "\n",
    "# Plot shaded areas for Neighbourhood\n",
    "ax.fill_between(times_nearest, perc_lst1, perc_lst4, color=color2, alpha=0.4)  # Increased opacity\n",
    "ax.fill_between(times_nearest, perc_lst2, perc_lst3, color=color2, alpha=0.6)  # Increased opacity\n",
    "ax.plot(times_nearest, perc_lst5, color='red', lw=2.5, label='Neighbourhood', zorder=10)\n",
    "ax.plot(times_nearest, tp1_midnight_edt, color='red', lw=2.5, label='Extremes-DT', zorder=10, linestyle = 'dashed')\n",
    "\n",
    "# Plot the observation data as black dots at the corresponding midnight times\n",
    "# included NaN for obs if these are not yet available\n",
    "obs_loc = list(obs_loc)\n",
    "if len(my_dates) > len(obs_loc):\n",
    "    for i in range(len(my_dates) - len(obs_loc)):\n",
    "        obs_loc.append(np.nan)\n",
    "        \n",
    "ax.plot(my_dates, obs_loc, 'ko', markersize=8, label='Observations', zorder=15)  # Black dots for observations\n",
    "\n",
    "# Set the x-axis limit up to 2024-09-17\n",
    "#end_date = np.datetime64('2025-04-08')\n",
    "end_date = adate + timedelta(hours=120)\n",
    "ax.set_xlim([d_times_six_hour[0:][0], end_date])\n",
    "\n",
    "# Adding labels, title, and grid\n",
    "ax.set_xlabel('Time', fontsize=12)\n",
    "ax.set_ylabel('6-Hour Accumulated Precipitation', fontsize=12)\n",
    "ax.set_title('6-Hour Accumulated Precipitation, '+location_name+', lat/lon: '+str(location[0])+' / '+str(location[1]), fontsize=14)\n",
    "ax.grid(True)\n",
    "\n",
    "# Format the x-axis to show the dates better\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "# Adding a simplified legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "percentile_patch = plt.Line2D([0], [0], color='grey', lw=1.5, label='Percentile ranges (1-99, 25-75)')\n",
    "mean_patch = plt.Line2D([0], [0], color='black', lw=2.5, label='Ensemble median')\n",
    "\n",
    "# Custom legend with example for percentiles and mean\n",
    "ax.legend(handles=[percentile_patch] + handles, \n",
    "          labels=['Percentile ranges (1-99, 25-75)',\n",
    "                  'oper ENS 50 member, median', 'oper control','Neighbourhood method from Extremes-DT, median', 'Extremes-DT', 'Observations'],\n",
    "          loc='upper right', fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80839409-177c-4952-b912-2b382bb2b594",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd321a-06f0-4137-afcf-2be2271b177f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
